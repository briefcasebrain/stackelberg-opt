{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Features of stackelberg-opt\n",
    "\n",
    "This notebook explores advanced features including:\n",
    "- Custom evaluation metrics\n",
    "- Semantic constraint extraction\n",
    "- Population management strategies\n",
    "- Checkpointing and recovery\n",
    "- Visualization tools\n",
    "- Performance optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required components\n",
    "from stackelberg_opt import *\n",
    "from stackelberg_opt.components import *\n",
    "from stackelberg_opt.utils import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import asyncio\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Set up visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Advanced features loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Semantic Constraint Extraction\n",
    "\n",
    "Extract and analyze constraints from module prompts and execution traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a system with explicit constraints\n",
    "constrained_modules = {\n",
    "    \"validator\": Module(\n",
    "        name=\"validator\",\n",
    "        prompt=\"\"\"You MUST validate all inputs before processing.\n",
    "ALWAYS check for: length limits, format requirements, and security issues.\n",
    "You should prefer structured output formats.\n",
    "Never process inputs longer than 1000 characters.\n",
    "Ensure all outputs are JSON-compatible.\"\"\",\n",
    "        module_type=ModuleType.LEADER,\n",
    "        dependencies=[]\n",
    "    ),\n",
    "    \"processor\": Module(\n",
    "        name=\"processor\",\n",
    "        prompt=\"\"\"Process the validated input according to these rules:\n",
    "- Must maintain data integrity\n",
    "- Should optimize for speed when possible\n",
    "- Always log processing steps\"\"\",\n",
    "        module_type=ModuleType.FOLLOWER,\n",
    "        dependencies=[\"validator\"]\n",
    "    )\n",
    "}\n",
    "\n",
    "# Extract constraints\n",
    "constraint_extractor = SemanticConstraintExtractor()\n",
    "leader_constraints = constraint_extractor.extract_constraints(\n",
    "    \"validator\",\n",
    "    constrained_modules[\"validator\"],\n",
    "    {}  # No traces yet\n",
    ")\n",
    "\n",
    "print(\"Extracted Constraints for Leader Module:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nHard constraints ({len(leader_constraints['hard'])}):\") \n",
    "for constraint in leader_constraints['hard']:\n",
    "    print(f\"  - {constraint}\")\n",
    "\n",
    "print(f\"\\nSoft constraints ({len(leader_constraints['soft'])}):\") \n",
    "for constraint in leader_constraints['soft']:\n",
    "    print(f\"  - {constraint}\")\n",
    "\n",
    "print(f\"\\nImplicit constraints ({len(leader_constraints['implicit'])}):\") \n",
    "for constraint in leader_constraints['implicit']:\n",
    "    print(f\"  - {constraint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Population Management\n",
    "\n",
    "Explore different selection strategies and archive management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a population manager with custom settings\n",
    "pop_manager = PopulationManager(\n",
    "    max_size=20,\n",
    "    elite_size=5,\n",
    "    diversity_weight=0.3,\n",
    "    innovation_weight=0.2,\n",
    "    selection_pressure=2.0\n",
    ")\n",
    "\n",
    "# Create diverse candidates\n",
    "print(\"Creating diverse population...\")\n",
    "for i in range(15):\n",
    "    # Create candidate with varying scores\n",
    "    candidate = SystemCandidate(\n",
    "        modules=constrained_modules.copy(),\n",
    "        candidate_id=i,\n",
    "        generation=0\n",
    "    )\n",
    "    \n",
    "    # Simulate different performance profiles\n",
    "    if i < 5:  # High performers\n",
    "        candidate.scores = {j: 0.8 + np.random.rand() * 0.2 for j in range(3)}\n",
    "    elif i < 10:  # Medium performers\n",
    "        candidate.scores = {j: 0.5 + np.random.rand() * 0.3 for j in range(3)}\n",
    "    else:  # Diverse/innovative candidates\n",
    "        candidate.scores = {j: 0.3 + np.random.rand() * 0.4 for j in range(3)}\n",
    "    \n",
    "    candidate.equilibrium_value = np.random.rand()\n",
    "    candidate.stability_score = np.random.rand()\n",
    "    \n",
    "    added, reason = pop_manager.add_candidate(candidate, i // 5)\n",
    "    if added:\n",
    "        print(f\"  Added candidate {i}: {reason}\")\n",
    "\n",
    "# Display population statistics\n",
    "stats = pop_manager.get_statistics()\n",
    "print(f\"\\nPopulation Statistics:\")\n",
    "print(f\"  Total population: {stats['population_size']}\")\n",
    "print(f\"  Elite archive: {stats['elite_size']}\")\n",
    "print(f\"  Diversity archive: {stats['diversity_size']}\")\n",
    "print(f\"  Innovation archive: {stats['innovation_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different parent selection strategies\n",
    "selection_methods = ['tournament', 'roulette', 'diverse', 'elite']\n",
    "selection_results = {}\n",
    "\n",
    "print(\"Testing Parent Selection Strategies:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for method in selection_methods:\n",
    "    parents = pop_manager.select_parents(n=5, method=method)\n",
    "    avg_fitness = np.mean([p.get_average_score() for p in parents])\n",
    "    \n",
    "    selection_results[method] = {\n",
    "        'parents': parents,\n",
    "        'avg_fitness': avg_fitness,\n",
    "        'ids': [p.candidate_id for p in parents]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{method.capitalize()} Selection:\")\n",
    "    print(f\"  Selected IDs: {selection_results[method]['ids']}\")\n",
    "    print(f\"  Average fitness: {avg_fitness:.3f}\")\n",
    "\n",
    "# Visualize selection bias\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "methods = list(selection_results.keys())\n",
    "avg_scores = [selection_results[m]['avg_fitness'] for m in methods]\n",
    "\n",
    "bars = ax.bar(methods, avg_scores, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "ax.set_ylabel('Average Fitness of Selected Parents')\n",
    "ax.set_title('Parent Selection Strategy Comparison')\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, score in zip(bars, avg_scores):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{score:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Evaluation Metrics\n",
    "\n",
    "Implement custom evaluation metrics for domain-specific optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEvaluator:\n",
    "    \"\"\"Custom evaluator with domain-specific metrics.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_evaluator):\n",
    "        self.base_evaluator = base_evaluator\n",
    "        self.custom_metrics = {}\n",
    "    \n",
    "    def add_metric(self, name: str, weight: float, metric_fn):\n",
    "        \"\"\"Add a custom metric to the evaluation.\"\"\"\n",
    "        self.custom_metrics[name] = {\n",
    "            'weight': weight,\n",
    "            'function': metric_fn\n",
    "        }\n",
    "    \n",
    "    async def evaluate_with_custom_metrics(self, candidate, input_data, expected_output):\n",
    "        \"\"\"Evaluate candidate with base + custom metrics.\"\"\"\n",
    "        # Get base evaluation\n",
    "        output, trace = await self.base_evaluator(candidate.modules, input_data)\n",
    "        \n",
    "        # Calculate base score\n",
    "        base_score = self.base_evaluator._calculate_score(output, expected_output, trace)\n",
    "        \n",
    "        # Calculate custom metrics\n",
    "        custom_scores = {}\n",
    "        for metric_name, metric_info in self.custom_metrics.items():\n",
    "            score = metric_info['function'](output, trace, candidate)\n",
    "            custom_scores[metric_name] = score * metric_info['weight']\n",
    "        \n",
    "        # Combine scores\n",
    "        total_weight = 1.0 + sum(m['weight'] for m in self.custom_metrics.values())\n",
    "        final_score = (base_score + sum(custom_scores.values())) / total_weight\n",
    "        \n",
    "        # Store detailed metrics in trace\n",
    "        trace.custom_metrics = custom_scores\n",
    "        trace.final_score = final_score\n",
    "        \n",
    "        return output, trace\n",
    "\n",
    "# Define custom metrics\n",
    "def response_time_metric(output, trace, candidate):\n",
    "    \"\"\"Penalize slow responses.\"\"\"\n",
    "    total_time = sum(trace.module_timings.values())\n",
    "    # Score decreases with time (max 1.0 for instant, 0.0 for >1 second)\n",
    "    return max(0, 1 - total_time)\n",
    "\n",
    "def consistency_metric(output, trace, candidate):\n",
    "    \"\"\"Reward consistent module scores.\"\"\"\n",
    "    if trace.intermediate_scores:\n",
    "        scores = list(trace.intermediate_scores.values())\n",
    "        return 1 - np.std(scores)  # Lower variance = higher score\n",
    "    return 0.5\n",
    "\n",
    "def innovation_metric(output, trace, candidate):\n",
    "    \"\"\"Reward novel outputs.\"\"\"\n",
    "    # Simple proxy: length variation from average\n",
    "    avg_length = 100  # Assumed average\n",
    "    length_diff = abs(len(str(output)) - avg_length) / avg_length\n",
    "    return min(1.0, length_diff * 2)  # Cap at 1.0\n",
    "\n",
    "# Create mock base evaluator\n",
    "async def mock_base_evaluator(modules, input_data):\n",
    "    trace = ExecutionTrace()\n",
    "    trace.module_timings = {'mod1': 0.1, 'mod2': 0.2}\n",
    "    trace.intermediate_scores = {'mod1': 0.8, 'mod2': 0.7}\n",
    "    trace.success = True\n",
    "    return \"Mock output\", trace\n",
    "\n",
    "mock_base_evaluator._calculate_score = lambda o, e, t: 0.75\n",
    "\n",
    "# Set up custom evaluator\n",
    "custom_eval = CustomEvaluator(mock_base_evaluator)\n",
    "custom_eval.add_metric('response_time', 0.2, response_time_metric)\n",
    "custom_eval.add_metric('consistency', 0.15, consistency_metric)\n",
    "custom_eval.add_metric('innovation', 0.1, innovation_metric)\n",
    "\n",
    "print(\"Custom evaluator configured with metrics:\")\n",
    "for name, info in custom_eval.custom_metrics.items():\n",
    "    print(f\"  - {name}: weight={info['weight']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Checkpointing and Recovery\n",
    "\n",
    "Demonstrate saving and loading optimization state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint manager\n",
    "checkpoint_dir = Path(\"optimization_checkpoints\")\n",
    "checkpoint_manager = CheckpointManager(checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "# Create auto-checkpointer\n",
    "auto_checkpointer = AutoCheckpointer(\n",
    "    checkpoint_manager,\n",
    "    time_interval=300,  # Every 5 minutes\n",
    "    iteration_interval=10  # Every 10 iterations\n",
    ")\n",
    "\n",
    "# Simulate optimization state\n",
    "optimization_state = {\n",
    "    'generation': 15,\n",
    "    'evaluations_used': 150,\n",
    "    'best_candidate': pop_manager.get_best_candidate(),\n",
    "    'population': pop_manager.population[:5],  # Save subset\n",
    "    'generation_stats': {\n",
    "        14: {'avg_fitness': 0.65, 'best_fitness': 0.82},\n",
    "        15: {'avg_fitness': 0.68, 'best_fitness': 0.85}\n",
    "    },\n",
    "    'config': {\n",
    "        'budget': 1000,\n",
    "        'population_size': 20,\n",
    "        'mutation_rate': 0.7\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save checkpoint\n",
    "checkpoint_name = \"optimization_example\"\n",
    "checkpoint_manager.save_checkpoint(optimization_state, checkpoint_name)\n",
    "print(f\"Checkpoint saved: {checkpoint_name}\")\n",
    "\n",
    "# List available checkpoints\n",
    "checkpoints = checkpoint_manager.list_checkpoints()\n",
    "print(f\"\\nAvailable checkpoints:\")\n",
    "for cp in checkpoints:\n",
    "    print(f\"  - {cp['name']} (created: {cp['created']})\")\n",
    "    if 'summary' in cp:\n",
    "        print(f\"    Generation: {cp['summary'].get('generation', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint and verify\n",
    "loaded_state = checkpoint_manager.load_checkpoint(checkpoint_name)\n",
    "\n",
    "print(\"Loaded checkpoint contents:\")\n",
    "print(f\"  Generation: {loaded_state['generation']}\")\n",
    "print(f\"  Evaluations used: {loaded_state['evaluations_used']}\")\n",
    "print(f\"  Population size: {len(loaded_state['population'])}\")\n",
    "print(f\"  Config: {json.dumps(loaded_state['config'], indent=2)}\")\n",
    "\n",
    "# Verify best candidate\n",
    "if loaded_state['best_candidate']:\n",
    "    best = loaded_state['best_candidate']\n",
    "    print(f\"\\nBest candidate from checkpoint:\")\n",
    "    print(f\"  ID: {best.candidate_id}\")\n",
    "    print(f\"  Average score: {best.get_average_score():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Visualization\n",
    "\n",
    "Create comprehensive visualizations of the optimization process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic optimization history for visualization\n",
    "def generate_synthetic_history(generations=20):\n",
    "    \"\"\"Generate synthetic optimization history.\"\"\"\n",
    "    history = {}\n",
    "    \n",
    "    for gen in range(generations):\n",
    "        # Simulate improving performance\n",
    "        base_fitness = 0.4 + (gen / generations) * 0.4\n",
    "        history[gen] = {\n",
    "            'avg_fitness': base_fitness + np.random.normal(0, 0.05),\n",
    "            'best_fitness': base_fitness + 0.1 + np.random.normal(0, 0.02),\n",
    "            'diversity': 0.5 * np.exp(-gen/10) + 0.2,  # Decreasing diversity\n",
    "            'innovations': max(0, int(5 * np.exp(-gen/5) + np.random.normal(0, 1))),\n",
    "            'equilibrium': 0.5 + (gen / generations) * 0.3 + np.random.normal(0, 0.03),\n",
    "            'stability': 0.6 + (gen / generations) * 0.2 + np.random.normal(0, 0.02)\n",
    "        }\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Create synthetic history\n",
    "synthetic_history = generate_synthetic_history(25)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Comprehensive Optimization Analysis', fontsize=16)\n",
    "\n",
    "generations = list(synthetic_history.keys())\n",
    "\n",
    "# 1. Fitness progression\n",
    "ax1 = axes[0, 0]\n",
    "avg_fitness = [synthetic_history[g]['avg_fitness'] for g in generations]\n",
    "best_fitness = [synthetic_history[g]['best_fitness'] for g in generations]\n",
    "ax1.plot(generations, avg_fitness, 'b-', label='Average', linewidth=2)\n",
    "ax1.plot(generations, best_fitness, 'r-', label='Best', linewidth=2)\n",
    "ax1.fill_between(generations, avg_fitness, best_fitness, alpha=0.3)\n",
    "ax1.set_title('Fitness Evolution')\n",
    "ax1.set_xlabel('Generation')\n",
    "ax1.set_ylabel('Fitness Score')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Diversity over time\n",
    "ax2 = axes[0, 1]\n",
    "diversity = [synthetic_history[g]['diversity'] for g in generations]\n",
    "ax2.plot(generations, diversity, 'g-', linewidth=2)\n",
    "ax2.set_title('Population Diversity')\n",
    "ax2.set_xlabel('Generation')\n",
    "ax2.set_ylabel('Diversity Score')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Innovation frequency\n",
    "ax3 = axes[0, 2]\n",
    "innovations = [synthetic_history[g]['innovations'] for g in generations]\n",
    "ax3.bar(generations, innovations, color='orange', alpha=0.7)\n",
    "ax3.set_title('Innovation Frequency')\n",
    "ax3.set_xlabel('Generation')\n",
    "ax3.set_ylabel('Number of Innovations')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Equilibrium vs Performance\n",
    "ax4 = axes[1, 0]\n",
    "equilibrium = [synthetic_history[g]['equilibrium'] for g in generations]\n",
    "ax4.scatter(best_fitness, equilibrium, c=generations, cmap='viridis', s=50)\n",
    "ax4.set_title('Equilibrium vs Performance')\n",
    "ax4.set_xlabel('Best Fitness')\n",
    "ax4.set_ylabel('Equilibrium Value')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(ax4.collections[0], ax=ax4)\n",
    "cbar.set_label('Generation')\n",
    "\n",
    "# 5. Stability progression\n",
    "ax5 = axes[1, 1]\n",
    "stability = [synthetic_history[g]['stability'] for g in generations]\n",
    "ax5.plot(generations, stability, 'm-', linewidth=2)\n",
    "ax5.fill_between(generations, stability, alpha=0.3, color='magenta')\n",
    "ax5.set_title('System Stability')\n",
    "ax5.set_xlabel('Generation')\n",
    "ax5.set_ylabel('Stability Score')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Multi-objective radar chart\n",
    "ax6 = axes[1, 2]\n",
    "# Get final generation metrics\n",
    "final_gen = max(generations)\n",
    "final_metrics = synthetic_history[final_gen]\n",
    "\n",
    "categories = ['Fitness', 'Equilibrium', 'Stability', 'Diversity']\n",
    "values = [\n",
    "    final_metrics['best_fitness'],\n",
    "    final_metrics['equilibrium'],\n",
    "    final_metrics['stability'],\n",
    "    final_metrics['diversity']\n",
    "]\n",
    "\n",
    "# Create radar chart\n",
    "angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "values += values[:1]  # Complete the circle\n",
    "angles += angles[:1]\n",
    "\n",
    "ax6 = plt.subplot(2, 3, 6, projection='polar')\n",
    "ax6.plot(angles, values, 'o-', linewidth=2, color='red')\n",
    "ax6.fill(angles, values, alpha=0.25, color='red')\n",
    "ax6.set_theta_offset(np.pi / 2)\n",
    "ax6.set_theta_direction(-1)\n",
    "ax6.set_xticks(angles[:-1])\n",
    "ax6.set_xticklabels(categories)\n",
    "ax6.set_ylim(0, 1)\n",
    "ax6.set_title('Final Multi-Objective Profile')\n",
    "ax6.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Optimization with Caching\n",
    "\n",
    "Demonstrate the caching system for improved performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create caching system\n",
    "llm_cache = LLMCache(cache_dir=Path(\"llm_cache\"))\n",
    "computation_cache = ComputationCache(max_size=1000)\n",
    "\n",
    "# Simulate LLM calls with caching\n",
    "print(\"Testing LLM Cache:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "prompts = [\n",
    "    \"Optimize this prompt for clarity\",\n",
    "    \"Optimize this prompt for clarity\",  # Duplicate\n",
    "    \"Generate a summary of the text\",\n",
    "    \"Optimize this prompt for clarity\"  # Another duplicate\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    # Check cache first\n",
    "    cached_response = llm_cache.get(prompt, \"gpt-3.5-turbo\", 0.7)\n",
    "    \n",
    "    if cached_response:\n",
    "        print(f\"\\nCall {i+1}: CACHE HIT\")\n",
    "        print(f\"  Prompt: {prompt}\")\n",
    "        print(f\"  Response: {cached_response[:50]}...\")\n",
    "    else:\n",
    "        print(f\"\\nCall {i+1}: CACHE MISS\")\n",
    "        print(f\"  Prompt: {prompt}\")\n",
    "        # Simulate LLM response\n",
    "        response = f\"Optimized version of '{prompt}'\"\n",
    "        llm_cache.set(prompt, \"gpt-3.5-turbo\", 0.7, response)\n",
    "        print(f\"  Response: {response}\")\n",
    "\n",
    "# Display cache statistics\n",
    "cache_stats = llm_cache.get_stats()\n",
    "print(f\"\\nCache Statistics:\")\n",
    "print(f\"  Total entries: {cache_stats['total_entries']}\")\n",
    "print(f\"  Cache size: {cache_stats['cache_size_bytes']} bytes\")\n",
    "print(f\"  Hit rate: {2/4:.1%} (2 hits out of 4 calls)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test computation cache with complex operations\n",
    "print(\"\\nTesting Computation Cache:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def expensive_computation(x, y, operation='multiply'):\n",
    "    \"\"\"Simulate expensive computation.\"\"\"\n",
    "    import time\n",
    "    time.sleep(0.1)  # Simulate delay\n",
    "    \n",
    "    if operation == 'multiply':\n",
    "        return x * y\n",
    "    elif operation == 'power':\n",
    "        return x ** y\n",
    "    else:\n",
    "        return x + y\n",
    "\n",
    "# Test caching\n",
    "test_cases = [\n",
    "    (10, 20, 'multiply'),\n",
    "    (10, 20, 'multiply'),  # Cache hit\n",
    "    (5, 3, 'power'),\n",
    "    (10, 20, 'multiply'),  # Another cache hit\n",
    "    (5, 3, 'power')  # Cache hit\n",
    "]\n",
    "\n",
    "import time\n",
    "\n",
    "for x, y, op in test_cases:\n",
    "    # Create cache key\n",
    "    cache_key = computation_cache.make_key('expensive_computation', x=x, y=y, operation=op)\n",
    "    \n",
    "    # Check cache\n",
    "    cached_result = computation_cache.get(cache_key)\n",
    "    \n",
    "    if cached_result is not None:\n",
    "        print(f\"\\nCACHE HIT: {op}({x}, {y}) = {cached_result}\")\n",
    "        print(\"  Time saved: ~0.1 seconds\")\n",
    "    else:\n",
    "        print(f\"\\nCACHE MISS: Computing {op}({x}, {y})...\")\n",
    "        start_time = time.time()\n",
    "        result = expensive_computation(x, y, op)\n",
    "        computation_time = time.time() - start_time\n",
    "        \n",
    "        # Store in cache\n",
    "        computation_cache.set(cache_key, result)\n",
    "        \n",
    "        print(f\"  Result: {result}\")\n",
    "        print(f\"  Computation time: {computation_time:.3f} seconds\")\n",
    "\n",
    "# Display computation cache stats\n",
    "comp_stats = computation_cache.get_stats()\n",
    "print(f\"\\nComputation Cache Statistics:\")\n",
    "print(f\"  Total entries: {comp_stats['total_entries']}\")\n",
    "print(f\"  Total accesses: {comp_stats['total_accesses']}\")\n",
    "print(f\"  Cache efficiency: {3/5:.1%} (3 hits out of 5 calls)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Integration Example: Complete Advanced System\n",
    "\n",
    "Combine all advanced features in a complete example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedOptimizationSystem:\n",
    "    \"\"\"Complete system using all advanced features.\"\"\"\n",
    "    \n",
    "    def __init__(self, modules: Dict[str, Module]):\n",
    "        self.modules = modules\n",
    "        \n",
    "        # Initialize components\n",
    "        self.constraint_extractor = SemanticConstraintExtractor()\n",
    "        self.dependency_analyzer = DependencyAnalyzer()\n",
    "        self.population_manager = PopulationManager(\n",
    "            max_size=30,\n",
    "            elite_size=8,\n",
    "            diversity_weight=0.35\n",
    "        )\n",
    "        \n",
    "        # Caching\n",
    "        self.llm_cache = LLMCache()\n",
    "        self.computation_cache = ComputationCache()\n",
    "        \n",
    "        # Checkpointing\n",
    "        self.checkpoint_manager = CheckpointManager()\n",
    "        self.auto_checkpointer = AutoCheckpointer(\n",
    "            self.checkpoint_manager,\n",
    "            iteration_interval=5\n",
    "        )\n",
    "        \n",
    "        # Visualization\n",
    "        self.visualizer = OptimizationVisualizer()\n",
    "        \n",
    "        # Extract initial constraints\n",
    "        self.constraints = self._extract_all_constraints()\n",
    "        \n",
    "    def _extract_all_constraints(self):\n",
    "        \"\"\"Extract constraints from all modules.\"\"\"\n",
    "        constraints = {}\n",
    "        for name, module in self.modules.items():\n",
    "            constraints[name] = self.constraint_extractor.extract_constraints(\n",
    "                name, module, {}\n",
    "            )\n",
    "        return constraints\n",
    "    \n",
    "    def analyze_system(self):\n",
    "        \"\"\"Comprehensive system analysis.\"\"\"\n",
    "        print(\"System Analysis Report\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Dependency analysis\n",
    "        dep_analysis = self.dependency_analyzer.analyze_dependencies(self.modules)\n",
    "        print(f\"\\n1. Dependency Structure:\")\n",
    "        print(f\"   - Is DAG: {dep_analysis['properties']['is_dag']}\")\n",
    "        print(f\"   - Max depth: {dep_analysis['properties']['max_depth']}\")\n",
    "        print(f\"   - Topological order: {dep_analysis['properties']['topological_order']}\")\n",
    "        \n",
    "        # Constraint summary\n",
    "        print(f\"\\n2. Constraint Summary:\")\n",
    "        for module_name, module_constraints in self.constraints.items():\n",
    "            total_constraints = (\n",
    "                len(module_constraints['hard']) +\n",
    "                len(module_constraints['soft']) +\n",
    "                len(module_constraints['implicit'])\n",
    "            )\n",
    "            print(f\"   - {module_name}: {total_constraints} total constraints\")\n",
    "        \n",
    "        # Module types\n",
    "        print(f\"\\n3. Module Distribution:\")\n",
    "        type_counts = {}\n",
    "        for module in self.modules.values():\n",
    "            type_name = module.module_type.value\n",
    "            type_counts[type_name] = type_counts.get(type_name, 0) + 1\n",
    "        \n",
    "        for type_name, count in type_counts.items():\n",
    "            print(f\"   - {type_name}: {count} modules\")\n",
    "    \n",
    "    def create_dashboard(self):\n",
    "        \"\"\"Create a comprehensive dashboard.\"\"\"\n",
    "        fig = plt.figure(figsize=(16, 10))\n",
    "        fig.suptitle('Advanced Optimization System Dashboard', fontsize=20)\n",
    "        \n",
    "        # Grid layout\n",
    "        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # Module type distribution (pie chart)\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        type_counts = {}\n",
    "        for module in self.modules.values():\n",
    "            type_name = module.module_type.value\n",
    "            type_counts[type_name] = type_counts.get(type_name, 0) + 1\n",
    "        \n",
    "        ax1.pie(type_counts.values(), labels=type_counts.keys(), autopct='%1.0f%%')\n",
    "        ax1.set_title('Module Type Distribution')\n",
    "        \n",
    "        # Constraint complexity (bar chart)\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        module_names = list(self.constraints.keys())\n",
    "        constraint_counts = [\n",
    "            len(self.constraints[m]['hard']) + \n",
    "            len(self.constraints[m]['soft'])\n",
    "            for m in module_names\n",
    "        ]\n",
    "        \n",
    "        ax2.bar(module_names, constraint_counts, color='skyblue')\n",
    "        ax2.set_title('Constraint Complexity by Module')\n",
    "        ax2.set_xlabel('Module')\n",
    "        ax2.set_ylabel('Number of Constraints')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Population statistics (if available)\n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "        pop_stats = self.population_manager.get_statistics()\n",
    "        stats_data = [\n",
    "            pop_stats['population_size'],\n",
    "            pop_stats['elite_size'],\n",
    "            pop_stats['diversity_size'],\n",
    "            pop_stats['innovation_size']\n",
    "        ]\n",
    "        stats_labels = ['Population', 'Elite', 'Diversity', 'Innovation']\n",
    "        \n",
    "        ax3.bar(stats_labels, stats_data, color=['blue', 'gold', 'green', 'red'])\n",
    "        ax3.set_title('Population Archives')\n",
    "        ax3.set_ylabel('Size')\n",
    "        \n",
    "        # Cache performance\n",
    "        ax4 = fig.add_subplot(gs[1, :])\n",
    "        cache_data = {\n",
    "            'LLM Cache Entries': self.llm_cache.get_stats()['total_entries'],\n",
    "            'Computation Cache Entries': self.computation_cache.get_stats()['total_entries'],\n",
    "            'Total Cache Accesses': self.computation_cache.get_stats()['total_accesses']\n",
    "        }\n",
    "        \n",
    "        ax4.barh(list(cache_data.keys()), list(cache_data.values()), color='purple')\n",
    "        ax4.set_title('Caching System Performance')\n",
    "        ax4.set_xlabel('Count')\n",
    "        \n",
    "        # System info text\n",
    "        ax5 = fig.add_subplot(gs[2, :])\n",
    "        ax5.axis('off')\n",
    "        \n",
    "        info_text = f\"\"\"System Configuration:\n",
    "        • Total Modules: {len(self.modules)}\n",
    "        • Population Size: {self.population_manager.max_size}\n",
    "        • Elite Archive Size: {self.population_manager.elite_size}\n",
    "        • Checkpoint Interval: {self.auto_checkpointer.iteration_interval} iterations\n",
    "        • Cache Hit Rate: Varies by usage pattern\n",
    "        \"\"\"\n",
    "        \n",
    "        ax5.text(0.1, 0.5, info_text, fontsize=12, verticalalignment='center',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "# Create advanced system\n",
    "advanced_modules = {\n",
    "    \"orchestrator\": Module(\n",
    "        name=\"orchestrator\",\n",
    "        prompt=\"Orchestrate the entire workflow. You MUST coordinate all modules.\",\n",
    "        module_type=ModuleType.LEADER,\n",
    "        dependencies=[]\n",
    "    ),\n",
    "    \"analyzer\": Module(\n",
    "        name=\"analyzer\",\n",
    "        prompt=\"Analyze inputs based on orchestrator guidance.\",\n",
    "        module_type=ModuleType.FOLLOWER,\n",
    "        dependencies=[\"orchestrator\"]\n",
    "    ),\n",
    "    \"optimizer\": Module(\n",
    "        name=\"optimizer\",\n",
    "        prompt=\"Optimize the analyzed results. Ensure maximum efficiency.\",\n",
    "        module_type=ModuleType.FOLLOWER,\n",
    "        dependencies=[\"analyzer\"]\n",
    "    ),\n",
    "    \"validator\": Module(\n",
    "        name=\"validator\",\n",
    "        prompt=\"Validate all outputs. Must check for errors and consistency.\",\n",
    "        module_type=ModuleType.INDEPENDENT,\n",
    "        dependencies=[\"optimizer\"]\n",
    "    )\n",
    "}\n",
    "\n",
    "# Initialize and analyze\n",
    "advanced_system = AdvancedOptimizationSystem(advanced_modules)\n",
    "advanced_system.analyze_system()\n",
    "\n",
    "# Create dashboard\n",
    "dashboard = advanced_system.create_dashboard()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated advanced features of stackelberg-opt:\n",
    "\n",
    "### Key Advanced Features:\n",
    "\n",
    "1. **Semantic Constraint Extraction**\n",
    "   - Automatically extract hard/soft constraints from prompts\n",
    "   - Analyze implicit requirements and dependencies\n",
    "\n",
    "2. **Advanced Population Management**\n",
    "   - Multiple selection strategies (tournament, roulette, diverse, elite)\n",
    "   - Separate archives for elite, diversity, and innovation\n",
    "   - Configurable selection pressure\n",
    "\n",
    "3. **Custom Evaluation Metrics**\n",
    "   - Add domain-specific metrics\n",
    "   - Weighted combination of multiple objectives\n",
    "   - Fine-grained performance analysis\n",
    "\n",
    "4. **Checkpointing and Recovery**\n",
    "   - Save/load optimization state\n",
    "   - Automatic checkpointing at intervals\n",
    "   - Resume interrupted optimizations\n",
    "\n",
    "5. **Advanced Visualization**\n",
    "   - Multi-faceted performance analysis\n",
    "   - Evolution tracking over generations\n",
    "   - Population diversity visualization\n",
    "   - Multi-objective radar charts\n",
    "\n",
    "6. **Performance Optimization**\n",
    "   - LLM response caching\n",
    "   - Computation result caching\n",
    "   - Significant speedup for repeated operations\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- **Use caching** for expensive LLM calls and computations\n",
    "- **Enable checkpointing** for long-running optimizations\n",
    "- **Monitor population diversity** to avoid premature convergence\n",
    "- **Extract and respect constraints** for valid optimizations\n",
    "- **Visualize progress** to understand optimization dynamics\n",
    "\n",
    "For production use, combine these features to create robust, efficient optimization systems tailored to your specific domain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}